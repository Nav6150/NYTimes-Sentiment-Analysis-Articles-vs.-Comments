{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f34de119",
   "metadata": {},
   "source": [
    "# Fetching New York Times Article Comments and Saving to CSV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "558cbc67",
   "metadata": {},
   "source": [
    "This Jupyter Notebook demonstrates how to read article URLs from a CSV file, fetch comments using the `nytimes_scraper` library, and save the comments to a CSV file."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d15dd368",
   "metadata": {},
   "source": [
    "## Step 1: Importing Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4e50c007",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll be using pandas to handle CSV files and the nytimes_scraper to fetch article comments.\n",
    "import pandas as pd\n",
    "from nytimes_scraper.nyt_api import NytApi\n",
    "from nytimes_scraper.comments import fetch_comments_by_article, comments_to_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5978f67",
   "metadata": {},
   "source": [
    "## Step 2: Initialize the NYTimes API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "607cc5aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# You need an API key from the New York Times Developer Portal.\n",
    "# Replace '<your_api_key>' with your actual API key.\n",
    "api = NytApi('a03qiFO9FwyMSp0po7kHavUoCNGTXpmY')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51336585",
   "metadata": {},
   "source": [
    "## Step 3: Read URLs from a CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2ab795de",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# This function reads a CSV file containing article URLs and returns them as a list.\n",
    "# We assume the CSV file has a column named 'article_url' which contains the URLs.\n",
    "def read_urls_from_csv(file_path):\n",
    "    \"\"\"\n",
    "    Reads a CSV file and extracts article URLs.\n",
    "\n",
    "    Parameters:\n",
    "    file_path (str): Path to the CSV file containing article URLs.\n",
    "\n",
    "    Returns:\n",
    "    List[str]: A list of article URLs.\n",
    "    \"\"\"\n",
    "    # Read the CSV file into a DataFrame\n",
    "    df = pd.read_csv('/Users/abhinav/Desktop/School/MSBA/2nd Semester/Advanced Programming/Code/Class/Week 4/currentarticles.csv')\n",
    "    \n",
    "    # Check and strip spaces from column names in case they exist\n",
    "    df.columns = df.columns.str.strip()\n",
    "    \n",
    "    # Print the column names for debugging in case there's a different column name\n",
    "    print(\"Columns in the CSV file:\", df.columns)\n",
    "    \n",
    "    # Extract URLs from the 'article_url' column (adjust the column name if necessary)\n",
    "    urls = df['web_url'].tolist()\n",
    "    \n",
    "    return urls\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "627ac919",
   "metadata": {},
   "source": [
    "## Step 4: Fetch Comments from the URLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "53e8cc26",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# This function fetches comments for a list of article URLs using the NYTimes API.\n",
    "def fetch_comments_for_urls(api, urls):\n",
    "    \"\"\"\n",
    "    Fetch comments for a list of article URLs.\n",
    "\n",
    "    Parameters:\n",
    "    api (NytApi): An instance of the NytApi class.\n",
    "    urls (List[str]): A list of article URLs.\n",
    "\n",
    "    Returns:\n",
    "    List[dict]: A list of comment dictionaries fetched from the articles.\n",
    "    \"\"\"\n",
    "    all_comments = []\n",
    "    \n",
    "    # Iterate through the list of URLs and fetch comments for each\n",
    "    for url in urls:\n",
    "        try:\n",
    "            print(f\"Fetching comments for: {url}\")\n",
    "            comments = fetch_comments_by_article(api, url)\n",
    "            all_comments.extend(comments)\n",
    "        except Exception as e:\n",
    "            print(f\"Error fetching comments for {url}: {e}\")\n",
    "    \n",
    "    return all_comments\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61ffbc4e",
   "metadata": {},
   "source": [
    "## Step 5: Save Comments to a CSV File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8e06cd61",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# This function takes a list of comments and saves them to a CSV file.\n",
    "def save_comments_to_csv(comments, output_file):\n",
    "    \"\"\"\n",
    "    Save comments to a CSV file.\n",
    "\n",
    "    Parameters:\n",
    "    comments (List[dict]): A list of comment dictionaries.\n",
    "    output_file (str): Path to the output CSV file.\n",
    "    \"\"\"\n",
    "    if comments:\n",
    "        # Convert the comments to a DataFrame\n",
    "        comment_df = comments_to_df(comments)\n",
    "        \n",
    "        # Save the DataFrame to a CSV file\n",
    "        comment_df.to_csv(output_file, index=False)\n",
    "        print(f\"Comments saved to {output_file}\")\n",
    "    else:\n",
    "        print(\"No comments found!\")\n",
    "#change so that it keeps the article ID --> Current articles tab, keep URl at least, adx_keywords, title"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39035eca",
   "metadata": {},
   "source": [
    "## Step 6: Main Function to Orchestrate the Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b5ac5250",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Main function to read article URLs, fetch comments, and save them to a CSV.\n",
    "def main(input_csv, output_csv):\n",
    "    \"\"\"\n",
    "    Main function to read article URLs, fetch comments, and save them to a CSV.\n",
    "\n",
    "    Parameters:\n",
    "    input_csv (str): Path to the input CSV file containing article URLs.\n",
    "    output_csv (str): Path to the output CSV file to save comments.\n",
    "    \"\"\"\n",
    "    # Step 6.1: Read article URLs from the input CSV\n",
    "    urls = read_urls_from_csv(input_csv)\n",
    "    \n",
    "    # Step 6.2: Fetch comments for the list of URLs\n",
    "    comments = fetch_comments_for_urls(api, urls)\n",
    "    \n",
    "    # Step 6.3: Save the fetched comments to the output CSV file\n",
    "    save_comments_to_csv(comments, output_csv)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae0b5498",
   "metadata": {},
   "source": [
    "## Step 7: Running the Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e45022ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns in the CSV file: Index(['Unnamed: 0', 'abstract', 'web_url', 'snippet', 'lead_paragraph',\n",
      "       'print_section', 'print_page', 'source', 'multimedia', 'headline',\n",
      "       'keywords', 'pub_date', 'document_type', 'news_desk', 'section_name',\n",
      "       'byline', 'type_of_material', '_id', 'word_count', 'uri',\n",
      "       'subsection_name'],\n",
      "      dtype='object')\n",
      "Fetching comments for: https://www.nytimes.com/2025/02/14/opinion/trump-tariffs-china-mexico.html\n",
      "Fetching comments for: https://www.nytimes.com/2025/02/13/us/politics/trump-tariffs.html\n",
      "Fetching comments for: https://www.nytimes.com/2025/02/01/us/politics/canada-mexico-china-trump-tariffs.html\n",
      "Fetching comments for: https://www.nytimes.com/2025/01/17/world/canada/canada-trump-tariffs.html\n",
      "Fetching comments for: https://www.nytimes.com/2025/01/20/us/politics/trump-tariffs-executive-order.html\n",
      "Fetching comments for: https://www.nytimes.com/2025/02/14/business/economy/whiskey-tariffs.html\n",
      "Fetching comments for: https://www.nytimes.com/2025/02/01/business/trump-tariffs-canada-mexico-china.html\n",
      "Fetching comments for: https://www.nytimes.com/2025/02/03/briefing/a-looming-trade-war.html\n",
      "Fetching comments for: https://www.nytimes.com/2025/01/31/us/politics/fed-tariffs-inflation-canada-mexico.html\n",
      "Fetching comments for: https://www.nytimes.com/2025/02/02/us/politics/trump-tariffs-global-economic-order.html\n",
      "Comments saved to nytimes_comments.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/nytimes_scraper/comments/postprocessing.py:21: FutureWarning: The behavior of 'to_datetime' with 'unit' when parsing strings is deprecated. In a future version, strings will be parsed as datetime strings, matching the behavior without a 'unit'. To retain the old behavior, explicitly cast ints or floats to numeric type before calling to_datetime.\n",
      "  df[col] = pd.to_datetime(df[col], unit='s')\n",
      "/opt/anaconda3/lib/python3.12/site-packages/nytimes_scraper/comments/postprocessing.py:21: FutureWarning: The behavior of 'to_datetime' with 'unit' when parsing strings is deprecated. In a future version, strings will be parsed as datetime strings, matching the behavior without a 'unit'. To retain the old behavior, explicitly cast ints or floats to numeric type before calling to_datetime.\n",
      "  df[col] = pd.to_datetime(df[col], unit='s')\n",
      "/opt/anaconda3/lib/python3.12/site-packages/nytimes_scraper/comments/postprocessing.py:21: FutureWarning: The behavior of 'to_datetime' with 'unit' when parsing strings is deprecated. In a future version, strings will be parsed as datetime strings, matching the behavior without a 'unit'. To retain the old behavior, explicitly cast ints or floats to numeric type before calling to_datetime.\n",
      "  df[col] = pd.to_datetime(df[col], unit='s')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Provide the path to the input CSV file containing article URLs and the output file to save the comments.\n",
    "input_csv = \"currentarticles.csv\"  # Example input file containing article URLs\n",
    "output_csv = \"nytimes_comments.csv\"     # Example output file to save fetched comments\n",
    "\n",
    "# Run the main function\n",
    "main(input_csv, output_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "020e209a-13ee-4c0e-a9f6-fda98ed9ab6c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
